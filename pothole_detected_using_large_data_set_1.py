# -*- coding: utf-8 -*-
"""Pothole Detected using large data set-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JWgfrgqovJ9Vr2gT8WIAyEffzLz9DUst
"""

! pip install -q kaggle

from google.colab import files
files.upload()

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets list

! kaggle datasets download -d atulyakumar98/pothole-detection-dataset

! mkdir pothole

! unzip pothole-detection-dataset.zip -d pothole

from google.colab import drive
drive.mount("/content/gdrive")

import numpy as np
import matplotlib.pyplot as plt
import cv2
import pandas as pd

# imagepaths = []
# import os
# for dirname, _, filenames in os.walk('/content/pothole'):
#     for filename in filenames:
#         path = os.path.join(dirname, filename)
#         imagepaths.append(path)

# print(len(imagepaths))

import os

IMG_SIZE=128

def imagePaths(folderpath):
  imagepaths = []
  for dirname, _, filenames in os.walk(folderpath):
      for filename in filenames:
          path = os.path.join(dirname, filename)
          imagepaths.append(path)
  print(len(imagepaths))
  return imagepaths

def addimages(imagepaths,label):
  for image in imagepaths:
      try:
          img = cv2.imread(image,cv2.IMREAD_GRAYSCALE)
          img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))
          x.append(np.array(img))
          if(label==0):
              y.append('NORMAL')
          else:
              y.append('POTHOLES')
      except:
          pass

x=[]
y=[]

p1 = imagePaths('/content/gdrive/MyDrive/Major/Potholes Dataset/Dataset 1 (Simplex)/Train data/Negative data')
addimages(p1,0)
print(len(x))
# print(y)

p1 = imagePaths('/content/gdrive/MyDrive/Major/Potholes Dataset/Dataset 1 (Simplex)/Train data/Positive data')
addimages(p1,1)
print(len(x))
# print(y)

p1 = imagePaths('/content/gdrive/MyDrive/Major/Potholes Dataset/Dataset 2 (Complex)/Train data/Negative data')
addimages(p1,0)
print(len(x))
# print(y)

p1 = imagePaths('/content/gdrive/MyDrive/Major/Potholes Dataset/Dataset 2 (Complex)/Train data/Positive data')
addimages(p1,1)
print(len(x))
# print(y)

print(len(x))
# print(y)

x=np.array(x)
y=np.array(y)

np.save('/content/gdrive/MyDrive/array.txt',x,True,True)

np.save('/content/gdrive/MyDrive/array_y.txt',y,allow_pickle=True)

x_l = np.load('/content/gdrive/MyDrive/array.txt.npy')

y_l = np.load('/content/gdrive/MyDrive/array_y.txt.npy')

from google.colab import drive
drive.mount('/content/drive')

x = np.load('/content/drive/MyDrive/Major/finalX.npy')
y = np.load('/content/drive/MyDrive/Major/finalY.npy')

from sklearn.utils import shuffle
x,y = shuffle(x, y, random_state=5)

np.save('/content/gdrive/MyDrive/Major/X_shuff',x,True,True)

np.save('/content/gdrive/MyDrive/Major/Y_shuff',x,True,True)

print(len(y))
print(y)

import random as rn
fig,ax=plt.subplots(2,5)
plt.subplots_adjust(bottom=0.3, top=0.7, hspace=0)
fig.set_size_inches(15,15)

for i in range(2):
    for j in range(5):
        l=rn.randint(0,len(y))
        # print(imagepaths[l])
        ax[i,j].imshow(x[l][:,:,::-1])
        ax[i,j].set_title(y[l])
        ax[i,j].set_aspect('equal')

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

# from sklearn.metrics import confusion_matrix

# from glob import glob

from sklearn.preprocessing import LabelEncoder
from keras.utils.np_utils import to_categorical
from sklearn.model_selection import train_test_split

le=LabelEncoder()
Y=le.fit_transform(y)
Y=to_categorical(Y,2)
print(Y)
x=np.array(x)
x=x/255

x_train,x_test,y_train,y_test=train_test_split(x,Y,test_size=0.30,random_state=5)

from keras.models import Sequential
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers import Dense, Flatten, Dropout

model = Sequential()

model.add(Conv2D(32, (5,5), activation = 'relu', input_shape=(128,128,1)))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(64, (3, 3), activation='relu')) 
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu')) 
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu')) 
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu')) 
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())

model.add(Dropout(0.4))

model.add(Dense(128, activation='relu'))

model.add(Dense(2, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
print(model.summary())
training_history=model.fit(x_train, y_train, epochs= 100, batch_size=12, verbose=2, 
         validation_data=(x_test, y_test))

def render_training_history(training_history):
    loss = training_history.history['loss']
    val_loss = training_history.history['val_loss']

    accuracy = training_history.history['accuracy']
    val_accuracy = training_history.history['val_accuracy']

    plt.figure(figsize=(14, 4))

    plt.subplot(1, 2, 1)
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.plot(loss, label='Training set')
    plt.plot(val_loss, label='Test set', linestyle='--')
    plt.legend()
    plt.grid(linestyle='--', linewidth=1, alpha=0.5)

    plt.subplot(1, 2, 2)
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.plot(accuracy, label='Training set')
    plt.plot(val_accuracy, label='Test set', linestyle='--')
    plt.legend()
    plt.grid(linestyle='--', linewidth=1, alpha=0.5)

    plt.show()
render_training_history(training_history)

loss, accuracy = model.evaluate(x_test, y_test)

print('Test accuracy: {:2.2f}%'.format(accuracy*100))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
print(model.summary())
training_history=model.fit(x_train, y_train, epochs= 35, batch_size=12, verbose=2, 
         validation_data=(x_test, y_test))

model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")

def render_training_history(training_history):
    loss = training_history.history['loss']
    val_loss = training_history.history['val_loss']

    accuracy = training_history.history['accuracy']
    val_accuracy = training_history.history['val_accuracy']

    plt.figure(figsize=(14, 4))

    plt.subplot(1, 2, 1)
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.plot(loss, label='Training set')
    plt.plot(val_loss, label='Test set', linestyle='--')
    plt.legend()
    plt.grid(linestyle='--', linewidth=1, alpha=0.5)

    plt.subplot(1, 2, 2)
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.plot(accuracy, label='Training set')
    plt.plot(val_accuracy, label='Test set', linestyle='--')
    plt.legend()
    plt.grid(linestyle='--', linewidth=1, alpha=0.5)

    plt.show()
render_training_history(training_history)

loss, accuracy = model.evaluate(x_test, y_test)

print('Test accuracy: {:2.2f}%'.format(accuracy*100))

